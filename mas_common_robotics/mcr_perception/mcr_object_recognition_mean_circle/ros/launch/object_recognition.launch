<?xml version="1.0"?>
<launch>

  <arg name="workspace_finder_config_file" default="$(find mcr_scene_segmentation)/ros/config/workspace_constraints.yaml" />
  <arg name="object_constraints_config_file" default="$(find mcr_scene_segmentation)/ros/config/object_constraints.yaml" />
  <arg name="input_pointcloud_topic" default="/arm_cam3d/depth_registered/points" />
  <arg name="camera_frame" default="arm_cam3d_rgb_optical_frame" />
  <arg name="target_frame" default="odom" />
  <arg name="classifier" default="objects_test" />
  

  <!-- This launch file starts all the nodes that are needed to perform object recognition.
       The "classifier" argument should contain the name of the previously trained svm classifier. 
       The "labels" argument should contain the name of the saved label encoder for the classifer.
       Both sets of files should be under common/config -->

  <include file="$(find mcr_object_detection)/ros/launch/object_detection.launch" >
    <arg name="workspace_finder_config_file" value="$(arg workspace_finder_config_file)" />
    <arg name="object_constraints_config_file" value="$(arg object_constraints_config_file)" />
    <arg name="input_pointcloud_topic" value="$(arg input_pointcloud_topic)" />
    <arg name="camera_frame" default="$(arg camera_frame)" />
    <arg name="target_frame" default="$(arg target_frame)" />
  </include>

  <node pkg="mcr_object_recognition_mean_circle" type="object_recognizer" name="object_recognizer"
          output="screen" ns="mcr_perception">
    <param name="classifier" value="$(arg classifier)" type="str" />
  </node>

</launch>
